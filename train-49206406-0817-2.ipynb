{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68点いった！\n",
    "Data AugmentationとFineTuningしよう！\n",
    "わかりやすくなるようにいらんやつけそう\n",
    "\n",
    "DataAugmentation 完了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 犬と猫を分類するモデルを構築\n",
    "\n",
    "### 1. 画像の読み込み\n",
    "\n",
    "まずは簡単に画像の読み込みの方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1,'/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加終わり"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データオーギュメンテーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport PIL\\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator,array_to_img\\nimport os\\ndog_filepaths = glob('train/dog/*.jpg')\\ncat_filepaths = glob('train/cat/*.jpg')\\nx, t = [], []\\n# ImageDataGeneratorをつくる\\n# datagenは「45度の範囲でランダムに回転するやつ」など\\ndatagen = ImageDataGenerator(rotation_range=45)\\ndatagen2 = ImageDataGenerator(shear_range=0.85)\\ndatagen3 = ImageDataGenerator(horizontal_flip=0.3)\\ndatagen4 = ImageDataGenerator(vertical_flip=0.3)\\n#これだとデータのパス（dog_filepaths）中の各ファイルに対して、imgファイルを開いてnumpyに変換してx,tの配列にぶちこんでる\\nfor filepath in dog_filepaths:\\n    img  = Image.open(filepath)\\n    img = np.array(img)\\n    #img.shapeすると(224,224,3)\\n    x.append(img)\\n    t.append(np.array(0))\\n    #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\\n    img = img.reshape((1,) + img.shape)\\n     #img.shapeすると(1,224,224,3)\\n    g = datagen.flow(img, batch_size=1)\\n    for i in range(3):\\n        batches = g.next()\\n         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\\n        x.append(batches[0])\\n        t.append(np.array(0))\\n    #面倒くさいからg2,g3,g4も同時にぶちこんでる\\n    g2 = datagen2.flow(img, batch_size=1)\\n    for i in range(3):\\n        batches = g2.next()\\n        x.append(batches[0])\\n        t.append(np.array(0))\\n    g3 = datagen3.flow(img, batch_size=1)\\n    for i in range(3):\\n        batches = g3.next()\\n        x.append(batches[0])\\n        t.append(np.array(0))\\n    g4 = datagen4.flow(img, batch_size=1)\\n    for i in range(3):\\n        batches = g4.next()\\n        x.append(batches[0])\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import PIL\n",
    "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator,array_to_img\n",
    "import os\n",
    "dog_filepaths = glob('train/dog/*.jpg')\n",
    "cat_filepaths = glob('train/cat/*.jpg')\n",
    "x, t = [], []\n",
    "# ImageDataGeneratorをつくる\n",
    "# datagenは「45度の範囲でランダムに回転するやつ」など\n",
    "datagen = ImageDataGenerator(rotation_range=45)\n",
    "datagen2 = ImageDataGenerator(shear_range=0.85)\n",
    "datagen3 = ImageDataGenerator(horizontal_flip=0.3)\n",
    "datagen4 = ImageDataGenerator(vertical_flip=0.3)\n",
    "#これだとデータのパス（dog_filepaths）中の各ファイルに対して、imgファイルを開いてnumpyに変換してx,tの配列にぶちこんでる\n",
    "for filepath in dog_filepaths:\n",
    "    img  = Image.open(filepath)\n",
    "    img = np.array(img)\n",
    "    #img.shapeすると(224,224,3)\n",
    "    x.append(img)\n",
    "    t.append(np.array(0))\n",
    "    #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "     #img.shapeすると(1,224,224,3)\n",
    "    g = datagen.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g.next()\n",
    "         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    #面倒くさいからg2,g3,g4も同時にぶちこんでる\n",
    "    g2 = datagen2.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g2.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g3 = datagen3.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g3.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g4 = datagen4.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g4.next()\n",
    "        x.append(batches[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "終わり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` のフォルダに入っている画像を読み込みます。\n",
    "`glob` を利用すると簡単にファイルを検索できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_filepaths = glob('train/dog/*.jpg')\n",
    "cat_filepaths = glob('train/cat/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# pip install Pillow    or   python -m pip install Pillow\n",
    "\n",
    "# macOS\n",
    "# pip3 install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. クラスラベルの割り振り\n",
    "\n",
    "画像の読み込み方がわかったため、クラスのラベルを割り振っていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator,array_to_img\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力値:x, 目標値: t\n",
    "x, t = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGeneratorをつくる\n",
    "# datagenは「45度の範囲でランダムに回転するやつ」など\n",
    "datagen = ImageDataGenerator(rotation_range=45)\n",
    "datagen2 = ImageDataGenerator(shear_range=0.85)\n",
    "datagen3 = ImageDataGenerator(horizontal_flip=0.3)\n",
    "datagen4 = ImageDataGenerator(vertical_flip=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 犬\n",
    "for filepath in dog_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(0))  # 犬は 0 とする\n",
    "    \n",
    "    ###\n",
    "    \"\"\"\n",
    "    # ImageDataGeneratorをつくる\n",
    "    # datagenは「45度の範囲でランダムに回転するやつ」など\n",
    "    datagen = ImageDataGenerator(rotation_range=45)\n",
    "    datagen2 = ImageDataGenerator(shear_range=0.85)\n",
    "    datagen3 = ImageDataGenerator(horizontal_flip=0.3)\n",
    "    datagen4 = ImageDataGenerator(vertical_flip=0.3)\n",
    "    \"\"\"\n",
    "    #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "     #img.shapeすると(1,224,224,3)\n",
    "    g = datagen.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g.next()\n",
    "         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    #面倒くさいからg2,g3,g4も同時にぶちこんでる\n",
    "    g2 = datagen2.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g2.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g3 = datagen3.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g3.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g4 = datagen4.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g4.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = x[np.newaxis]\\nx.shape\\n# np.newaxis で次元をひとつ追加\\nx = x[np.newaxis]\\nx.shape\\n\\n>>> でもいいのでは？\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = x[np.newaxis]\n",
    "x.shape\n",
    "# np.newaxis で次元をひとつ追加\n",
    "x = x[np.newaxis]\n",
    "x.shape\n",
    "\n",
    ">>> でもいいのでは？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 猫\n",
    "for filepath in cat_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(1))  # 猫は 1 とする\n",
    "    \n",
    "    ##\n",
    "        \n",
    "     #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "     #img.shapeすると(1,224,224,3)\n",
    "    g = datagen.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g.next()\n",
    "         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    #面倒くさいからg2,g3,g4も同時にぶちこんでる\n",
    "    g2 = datagen2.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g2.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    g3 = datagen3.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g3.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    g4 = datagen4.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g4.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 3900)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格納された枚数\n",
    "len(x), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を numpy の形式に変換\n",
    "x = np.array(x)  # f は float32\n",
    "t = np.array(t)  # i は int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300(枚), 224(height), 224(width), 3(channels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x の値の範囲を正規化しておくと学習が効率的に進むことが多いため、こちらも行なっておきましょう。学習係数などを調整する場合など、必ず必要ではありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の正規化 (0~1の範囲に)\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow では訓練データ (train) と検証データ (val) を分ける機能がないため、scikit-learn の `train_test_split` を利用します。\n",
    "\n",
    "なお、テストデータ (test) は私の手元にしかないため、手持ちのデータの中で以下にテストデータを模擬的に表現できるかのために検証データがあります。精度を高めたいときには**交差検証法 (cross validation)** も選択肢としてあるため、こちらも必要であれば挑戦してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : val = 0.7 : 0.3 の割合で分割する\n",
    "train_x, val_x, train_t, val_t = train_test_split(x, t, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2730, 224, 224, 3), (2730,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（訓練データ）\n",
    "train_x.shape, train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1170, 224, 224, 3), (1170,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（検証データ）\n",
    "val_x.shape, val_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. モデルを定義\n",
    "\n",
    "今回は非常にシンプルな構成の CNN でモデルを構築します。あまり良い精度が出ないようにしてあるため、ここのモデルの構造を工夫して精度を高めましょう。\n",
    "\n",
    "ヒント\n",
    "- VGG, ResNet, MobileNet\n",
    "- ファインチューニング\n",
    "\n",
    "複雑なモデルを構築する場合には GPU がないと遅い場合もあるため、[こちらの手順](https://www.kikagaku.ai/tutorial/guide_for_beginners/learn/platform_environment) を参考に Google Colab を使ってみると良いでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バージョンの情報\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構築の際に乱数のシードも固定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの固定を実行\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow のモデルの定義に必要なモジュールを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のようなモデルを定義していきましょう。\n",
    "\n",
    "- Original: (224, 224, 3)\n",
    "- => Convolution (Relu) => (224, 224, 6)\n",
    "- => Half Pooling => (112, 112, 6)\n",
    "- => ベクトル化 (112×112×6)\n",
    "- => 全結合層 (112×112×6 => 100), Relu\n",
    "- => 全結合層 (100 => 2), Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "model = models.Sequential([\n",
    "    # Convolution\n",
    "    layers.Conv2D(3, kernel_size=(3,3), padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
    "    # Pooling\n",
    "    layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    # ベクトル化 (Flatten)\n",
    "    layers.Flatten(),\n",
    "    # 全結合層\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    # 全結合層\n",
    "    layers.Dense(2, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenrsoflow では定義したモデルをコンパイルする必要がありました。最適化のアルゴリズムを確率的勾配降下法 (SGD) として選択します。\n",
    "\n",
    "ここのアルゴリズムの選択と学習係数の設定も精度向上のポイントですので、[こちらの記事](https://www.tensorflow.org/guide/keras/train_and_evaluate) などを参考にしながら進めてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 18s 2s/step - loss: 1.3839 - accuracy: 0.5150 - val_loss: 0.7598 - val_accuracy: 0.5060\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.6302 - accuracy: 0.6256 - val_loss: 0.5923 - val_accuracy: 0.6513\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.4902 - accuracy: 0.7718 - val_loss: 0.4580 - val_accuracy: 0.8068\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3748 - accuracy: 0.8700 - val_loss: 0.3757 - val_accuracy: 0.8385\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.2808 - accuracy: 0.8996 - val_loss: 0.3191 - val_accuracy: 0.8496\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.2088 - accuracy: 0.9414 - val_loss: 0.2805 - val_accuracy: 0.8769\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.1508 - accuracy: 0.9667 - val_loss: 0.2595 - val_accuracy: 0.8872\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.1112 - accuracy: 0.9788 - val_loss: 0.2431 - val_accuracy: 0.8915\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.0818 - accuracy: 0.9883 - val_loss: 0.2441 - val_accuracy: 0.8846\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.0604 - accuracy: 0.9941 - val_loss: 0.2323 - val_accuracy: 0.8957\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.0463 - accuracy: 0.9960 - val_loss: 0.2392 - val_accuracy: 0.8949\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.0389 - accuracy: 0.9974 - val_loss: 0.2401 - val_accuracy: 0.8940\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.0324 - accuracy: 0.9982 - val_loss: 0.2360 - val_accuracy: 0.8940\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 0.2469 - val_accuracy: 0.8974\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.0194 - accuracy: 0.9989 - val_loss: 0.2548 - val_accuracy: 0.8991\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.0151 - accuracy: 0.9996 - val_loss: 0.2482 - val_accuracy: 0.9026\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.0124 - accuracy: 0.9996 - val_loss: 0.2573 - val_accuracy: 0.8983\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.0105 - accuracy: 0.9996 - val_loss: 0.2635 - val_accuracy: 0.9068\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9043\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9051\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "history = model.fit(\n",
    "    train_x, train_t,\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    "    validation_data=(val_x, val_t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train に関して accuracy が 0.76, validation に関しては accuracy が 0.49 となっており、**過学習 (overfitting)** が生じていることがわかります。\n",
    "\n",
    "この辺りも踏まえて、予測の精度を上げられるように色々な手法に挑戦してみましょう。比較的簡単なところでは以下を調整してみると良いでしょう。\n",
    "\n",
    "- モデルの構成（VGG, ResNet, MobileNet など）\n",
    "- ファイチューニング\n",
    "- 最適化アルゴリズムの選択\n",
    "- 学習係数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの保存\n",
    "\n",
    "推論にて使用するために学習済みモデルをファイルに出力しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 という形式で保存（TensorFlowではこちらを用いるようです）\n",
    "model.save('dog_cat_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで作業フォルダの中に `dog_cat_cnn.h5` というファイルが出力できていれば成功です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ONNX形式で出力\n",
    "\n",
    "ONNX は TensorFlow や PyTorch 問わず、モデルの形式を標準化するプロジェクトです。  \n",
    "最近では、こちらの形式に統一しておくほうが汎用性が高くなっているため、推論サーバーでは ONNX 形式を使用します。\n",
    "\n",
    "onnxruntime では通常よりも速度が速いと言われています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !pip install onnxruntime   or   !python -m pip install onnxruntime\n",
    "\n",
    "# macOS\n",
    "#!pip3 install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !pip install keras2onnx  or   !python -m pip install keras2onnx\n",
    "\n",
    "# macOS\n",
    "#!pip3 install keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import onnx\n",
    "import keras2onnx\n",
    "keras2onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n"
     ]
    }
   ],
   "source": [
    "# Keras -> ONNX の変換\n",
    "onnx_model = keras2onnx.convert_keras(model, model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを保存\n",
    "keras2onnx.save_model(onnx_model, 'dog_cat_cnn_90.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "session = onnxruntime.InferenceSession('dog_cat_cnn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論に必要な構造の抽出\n",
    "session.get_modelmeta()\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv2d_input', 'dense_1')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name, output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7187651 , 0.2812349 ],\n",
       "       [0.6928094 , 0.30719063],\n",
       "       [0.63302684, 0.36697313],\n",
       "       ...,\n",
       "       [0.03368696, 0.96631306],\n",
       "       [0.03368696, 0.96631306],\n",
       "       [0.03368696, 0.96631306]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論\n",
    "y_probs = session.run([output_name], {input_name: x})[0]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e876778c0925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ラベル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_prob' is not defined"
     ]
    }
   ],
   "source": [
    "# ラベル\n",
    "y = np.argmax(y_prob)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
