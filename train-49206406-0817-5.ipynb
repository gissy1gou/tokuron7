{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68点いった！\n",
    "Data AugmentationとFineTuningしよう！\n",
    "わかりやすくなるようにいらんやつけそう\n",
    "\n",
    "DataAugmentation 完了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 犬と猫を分類するモデルを構築\n",
    "\n",
    "### 1. 画像の読み込み\n",
    "\n",
    "まずは簡単に画像の読み込みの方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow',\n",
      " '/Applications/anaconda3/lib/python37.zip',\n",
      " '/Applications/anaconda3/lib/python3.7',\n",
      " '/Applications/anaconda3/lib/python3.7/lib-dynload',\n",
      " '',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/aeosa',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
      " '/Users/takekazukitagishi/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1,'/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow',\n",
      " '/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python37.zip',\n",
      " '/Applications/anaconda3/lib/python3.7',\n",
      " '/Applications/anaconda3/lib/python3.7/lib-dynload',\n",
      " '',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/aeosa',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
      " '/Users/takekazukitagishi/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加終わり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` のフォルダに入っている画像を読み込みます。\n",
    "`glob` を利用すると簡単にファイルを検索できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_filepaths = glob('train/dog/*.jpg')\n",
    "cat_filepaths = glob('train/cat/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. クラスラベルの割り振り\n",
    "\n",
    "画像の読み込み方がわかったため、クラスのラベルを割り振っていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator,array_to_img\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力値:x, 目標値: t\n",
    "x, t = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGeneratorをつくる\n",
    "# datagenは「45度の範囲でランダムに回転するやつ」など\n",
    "datagen = ImageDataGenerator(rotation_range=45)\n",
    "datagen2 = ImageDataGenerator(shear_range=0.85)\n",
    "datagen3 = ImageDataGenerator(horizontal_flip=0.3)\n",
    "datagen4 = ImageDataGenerator(vertical_flip=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 犬\n",
    "for filepath in dog_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(0))  # 犬は 0 とする\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "     #img.shapeすると(1,224,224,3)\n",
    "    g = datagen.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g.next()\n",
    "         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    #面倒くさいからg2,g3,g4も同時にぶちこんでる\n",
    "    g2 = datagen2.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g2.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g3 = datagen3.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g3.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))\n",
    "    g4 = datagen4.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g4.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 猫\n",
    "for filepath in cat_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(1))  # 猫は 1 とする\n",
    "    \n",
    "    ##\n",
    "        \n",
    "     #ImageDataGeneratorは4次元データじゃないと読み込まないっぽい\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "     #img.shapeすると(1,224,224,3)\n",
    "    g = datagen.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g.next()\n",
    "         #batchesは(1,224,224,3)になっているから、batchesの[0]番目の配列を指定してあげる\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    #面倒くさいからg2,g3,g4も同時にぶちこんでる\n",
    "    g2 = datagen2.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g2.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    g3 = datagen3.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g3.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    g4 = datagen4.flow(img, batch_size=1)\n",
    "    for i in range(3):\n",
    "        batches = g4.next()\n",
    "        x.append(batches[0])\n",
    "        t.append(np.array(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 3900)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格納された枚数\n",
    "len(x), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を numpy の形式に変換\n",
    "x = np.array(x)  # f は float32\n",
    "t = np.array(t)  # i は int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300(枚), 224(height), 224(width), 3(channels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x の値の範囲を正規化しておくと学習が効率的に進むことが多いため、こちらも行なっておきましょう。学習係数などを調整する場合など、必ず必要ではありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の正規化 (0~1の範囲に)\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow では訓練データ (train) と検証データ (val) を分ける機能がないため、scikit-learn の `train_test_split` を利用します。\n",
    "\n",
    "なお、テストデータ (test) は私の手元にしかないため、手持ちのデータの中で以下にテストデータを模擬的に表現できるかのために検証データがあります。精度を高めたいときには**交差検証法 (cross validation)** も選択肢としてあるため、こちらも必要であれば挑戦してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : val = 0.7 : 0.3 の割合で分割する\n",
    "train_x, val_x, train_t, val_t = train_test_split(x, t, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2730, 224, 224, 3), (2730,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（訓練データ）\n",
    "train_x.shape, train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1170, 224, 224, 3), (1170,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（検証データ）\n",
    "val_x.shape, val_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. モデルを定義\n",
    "\n",
    "今回は非常にシンプルな構成の CNN でモデルを構築します。あまり良い精度が出ないようにしてあるため、ここのモデルの構造を工夫して精度を高めましょう。\n",
    "\n",
    "ヒント\n",
    "- VGG, ResNet, MobileNet\n",
    "- ファインチューニング\n",
    "\n",
    "複雑なモデルを構築する場合には GPU がないと遅い場合もあるため、[こちらの手順](https://www.kikagaku.ai/tutorial/guide_for_beginners/learn/platform_environment) を参考に Google Colab を使ってみると良いでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バージョンの情報\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構築の際に乱数のシードも固定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの固定を実行\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow のモデルの定義に必要なモジュールを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のようなモデルを定義していきましょう。\n",
    "\n",
    "- Original: (224, 224, 3)\n",
    "- => Convolution (Relu) => (224, 224, 6)\n",
    "- => Half Pooling => (112, 112, 6)\n",
    "- => ベクトル化 (112×112×6)\n",
    "- => 全結合層 (112×112×6 => 100), Relu\n",
    "- => 全結合層 (100 => 2), Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = models.Sequential()\n",
    "\n",
    "conv_base.add(layers.Conv2D(3, kernel_size=(3,3), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "conv_base.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファインチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenrsoflow では定義したモデルをコンパイルする必要がありました。最適化のアルゴリズムを確率的勾配降下法 (SGD) として選択します。\n",
    "\n",
    "ここのアルゴリズムの選択と学習係数の設定も精度向上のポイントですので、[こちらの記事](https://www.tensorflow.org/guide/keras/train_and_evaluate) などを参考にしながら進めてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# モデルのコンパイル\\nmodel.compile(\\n    loss='binary_crossentropy',\\n    optimizer=optimizers.RMSprop(lr=2e-5),\\n    metrics=['acc']\\n)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 9s 775ms/step - loss: 1.2837 - accuracy: 0.5044 - val_loss: 0.8310 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 8s 744ms/step - loss: 0.6572 - accuracy: 0.5952 - val_loss: 0.6472 - val_accuracy: 0.5983\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 8s 758ms/step - loss: 0.5598 - accuracy: 0.7168 - val_loss: 0.5598 - val_accuracy: 0.7641\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 8s 756ms/step - loss: 0.5035 - accuracy: 0.8073 - val_loss: 0.5594 - val_accuracy: 0.6778\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 10s 874ms/step - loss: 0.4687 - accuracy: 0.7974 - val_loss: 0.4984 - val_accuracy: 0.7718\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 8s 755ms/step - loss: 0.4233 - accuracy: 0.8473 - val_loss: 0.4732 - val_accuracy: 0.7991\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 9s 799ms/step - loss: 0.3924 - accuracy: 0.8615 - val_loss: 0.4330 - val_accuracy: 0.8376\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.3499 - accuracy: 0.8974 - val_loss: 0.4245 - val_accuracy: 0.8308\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 8s 706ms/step - loss: 0.3241 - accuracy: 0.9132 - val_loss: 0.3914 - val_accuracy: 0.8479\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.2907 - accuracy: 0.9366 - val_loss: 0.3785 - val_accuracy: 0.8607\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 9s 831ms/step - loss: 0.2816 - accuracy: 0.9172 - val_loss: 0.4476 - val_accuracy: 0.7803\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 8s 760ms/step - loss: 0.2799 - accuracy: 0.9015 - val_loss: 0.3478 - val_accuracy: 0.8709\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.2524 - accuracy: 0.9187 - val_loss: 0.3979 - val_accuracy: 0.8077\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 0.2270 - accuracy: 0.9410 - val_loss: 0.3188 - val_accuracy: 0.8803\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 8s 771ms/step - loss: 0.1946 - accuracy: 0.9612 - val_loss: 0.3216 - val_accuracy: 0.8778\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 8s 764ms/step - loss: 0.1861 - accuracy: 0.9656 - val_loss: 0.3264 - val_accuracy: 0.8692\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 0.1704 - accuracy: 0.9674 - val_loss: 0.2937 - val_accuracy: 0.8803\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 8s 700ms/step - loss: 0.1597 - accuracy: 0.9718 - val_loss: 0.2865 - val_accuracy: 0.8855\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 8s 747ms/step - loss: 0.1519 - accuracy: 0.9678 - val_loss: 0.2833 - val_accuracy: 0.8829\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 8s 692ms/step - loss: 0.1418 - accuracy: 0.9729 - val_loss: 0.2829 - val_accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "history = model.fit(\n",
    "    train_x, train_t,\n",
    "    batch_size=256,\n",
    "    #epochs=2,\n",
    "    epochs=20,\n",
    "    validation_data=(val_x, val_t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train に関して accuracy が 0.76, validation に関しては accuracy が 0.49 となっており、**過学習 (overfitting)** が生じていることがわかります。\n",
    "\n",
    "この辺りも踏まえて、予測の精度を上げられるように色々な手法に挑戦してみましょう。比較的簡単なところでは以下を調整してみると良いでしょう。\n",
    "\n",
    "- モデルの構成（VGG, ResNet, MobileNet など）\n",
    "- ファイチューニング\n",
    "- 最適化アルゴリズムの選択\n",
    "- 学習係数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファインチューニング\n",
    "\n",
    "model をconv_baseと全結合層に分けて、conv_baseだけを取り出す\n",
    "\n",
    "一回、model.add()でも大丈夫かを確認しよう→大丈夫だった\n",
    "\n",
    "compileを変えて、ファインチューニングのをやってみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.compile(loss='binary_crossentropy',\\n              optimizer=optimizers.RMSprop(lr=2e-5),\\n              metrics=['acc'])\\n\\nhistory = model.fit_generator(\\n      train_generator,\\n      steps_per_epoch=100,\\n      #epochs=30,\\n      epochs=1,\\n      validation_data=validation_generator,\\n      validation_steps=50,\\n      verbose=2)\\n      \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      #epochs=30,\n",
    "      epochs=1,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 3)       84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 3)       0         \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 0\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'conv2d':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.compile(loss='binary_crossentropy',\\n              optimizer=optimizers.RMSprop(lr=1e-5),\\n              metrics=['acc'])\\n\\nhistory = model.fit_generator(\\n      train_generator,\\n      steps_per_epoch=100,\\n      #epochs=100,\\n      epochs=1,\\n      validation_data=validation_generator,\\n      validation_steps=50)\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      #epochs=100,\n",
    "      epochs=1,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# モデルのコンパイル\\nmodel.compile(\\n    loss='binary_crossentropy',\\n    optimizer=optimizers.RMSprop(lr=1e-5),\\n    metrics=['acc']\\n)\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "    metrics=['acc']\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 1.0613 - accuracy: 0.7161 - val_loss: 0.5070 - val_accuracy: 0.7248\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3147 - accuracy: 0.8996 - val_loss: 0.3808 - val_accuracy: 0.8590\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.2627 - accuracy: 0.9348 - val_loss: 0.3528 - val_accuracy: 0.8291\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.1889 - accuracy: 0.9476 - val_loss: 0.2864 - val_accuracy: 0.8735\n",
      "Epoch 5/10\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "history = model.fit(\n",
    "    train_x, train_t,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    #epochs=100,\n",
    "    #epochs=30,\n",
    "    validation_data=(val_x, val_t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの保存\n",
    "\n",
    "推論にて使用するために学習済みモデルをファイルに出力しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 という形式で保存（TensorFlowではこちらを用いるようです）\n",
    "model.save('dog_cat_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで作業フォルダの中に `dog_cat_cnn.h5` というファイルが出力できていれば成功です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ONNX形式で出力\n",
    "\n",
    "ONNX は TensorFlow や PyTorch 問わず、モデルの形式を標準化するプロジェクトです。  \n",
    "最近では、こちらの形式に統一しておくほうが汎用性が高くなっているため、推論サーバーでは ONNX 形式を使用します。\n",
    "\n",
    "onnxruntime では通常よりも速度が速いと言われています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !pip install onnxruntime   or   !python -m pip install onnxruntime\n",
    "\n",
    "# macOS\n",
    "#!pip3 install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !pip install keras2onnx  or   !python -m pip install keras2onnx\n",
    "\n",
    "# macOS\n",
    "#!pip3 install keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import onnx\n",
    "import keras2onnx\n",
    "keras2onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras -> ONNX の変換\n",
    "onnx_model = keras2onnx.convert_keras(model, model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを保存\n",
    "keras2onnx.save_model(onnx_model, 'dog_cat_cnn88.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "session = onnxruntime.InferenceSession('dog_cat_cnn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論に必要な構造の抽出\n",
    "session.get_modelmeta()\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name, output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論\n",
    "y_probs = session.run([output_name], {input_name: x})[0]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル\n",
    "y = np.argmax(y_prob)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
