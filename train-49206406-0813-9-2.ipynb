{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetで失敗\n",
    "Unable to find out a correct type for tensor type = 20 of normalization/Reshape_1/ReadVariableOp/resource:0\n",
    "\n",
    "\n",
    "VGGでFunctionalAPIではなくSequentialなやつでやってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 犬と猫を分類するモデルを構築\n",
    "\n",
    "### 1. 画像の読み込み\n",
    "\n",
    "まずは簡単に画像の読み込みの方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow',\n",
      " '/Applications/anaconda3/lib/python37.zip',\n",
      " '/Applications/anaconda3/lib/python3.7',\n",
      " '/Applications/anaconda3/lib/python3.7/lib-dynload',\n",
      " '',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/aeosa',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
      " '/Users/takekazukitagishi/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1,'/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow',\n",
      " '/Users/takekazukitagishi/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python37.zip',\n",
      " '/Applications/anaconda3/lib/python3.7',\n",
      " '/Applications/anaconda3/lib/python3.7/lib-dynload',\n",
      " '',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/aeosa',\n",
      " '/Applications/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
      " '/Users/takekazukitagishi/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import keras2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加終わり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` のフォルダに入っている画像を読み込みます。\n",
    "`glob` を利用すると簡単にファイルを検索できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_filepaths = glob('train/dog/*.jpg')\n",
    "cat_filepaths = glob('train/cat/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の通り、Pillow 独自の方を持っているため、計算で扱う場合には numpy の ndarray に変換しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. クラスラベルの割り振り\n",
    "\n",
    "画像の読み込み方がわかったため、クラスのラベルを割り振っていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力値:x, 目標値: t\n",
    "x, t = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 犬\n",
    "for filepath in dog_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(0))  # 犬は 0 とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 猫\n",
    "for filepath in cat_filepaths:\n",
    "    img = Image.open(filepath)\n",
    "    img = img.resize((224, 224))#追加\n",
    "    img = np.array(img)\n",
    "    x.append(img)\n",
    "    t.append(np.array(1))  # 猫は 0 とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格納された枚数\n",
    "len(x), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を numpy の形式に変換\n",
    "x = np.array(x)  # f は float32\n",
    "t = np.array(t)  # i は int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 300(枚), 224(height), 224(width), 3(channels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x の値の範囲を正規化しておくと学習が効率的に進むことが多いため、こちらも行なっておきましょう。学習係数などを調整する場合など、必ず必要ではありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の正規化 (0~1の範囲に)\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow では訓練データ (train) と検証データ (val) を分ける機能がないため、scikit-learn の `train_test_split` を利用します。\n",
    "\n",
    "なお、テストデータ (test) は私の手元にしかないため、手持ちのデータの中で以下にテストデータを模擬的に表現できるかのために検証データがあります。精度を高めたいときには**交差検証法 (cross validation)** も選択肢としてあるため、こちらも必要であれば挑戦してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : val = 0.7 : 0.3 の割合で分割する\n",
    "train_x, val_x, train_t, val_t = train_test_split(x, t, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 224, 224, 3), (210,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（訓練データ）\n",
    "train_x.shape, train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 224, 224, 3), (90,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サイズの確認（検証データ）\n",
    "val_x.shape, val_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. モデルを定義\n",
    "\n",
    "今回は非常にシンプルな構成の CNN でモデルを構築します。あまり良い精度が出ないようにしてあるため、ここのモデルの構造を工夫して精度を高めましょう。\n",
    "\n",
    "ヒント\n",
    "- VGG, ResNet, MobileNet\n",
    "- ファインチューニング\n",
    "\n",
    "複雑なモデルを構築する場合には GPU がないと遅い場合もあるため、[こちらの手順](https://www.kikagaku.ai/tutorial/guide_for_beginners/learn/platform_environment) を参考に Google Colab を使ってみると良いでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構築の際に乱数のシードも固定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの固定を実行\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のようなモデルを定義していきましょう。\n",
    "\n",
    "- Original: (224, 224, 3)\n",
    "- => Convolution (Relu) => (224, 224, 6)\n",
    "- => Half Pooling => (112, 112, 6)\n",
    "- => ベクトル化 (112×112×6)\n",
    "- => 全結合層 (112×112×6 => 100), Relu\n",
    "- => 全結合層 (100 => 2), Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "input_shape = (224, 224, 3)\n",
    "class_count = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "model = models.Sequential([\n",
    "    # Convolution\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Pooling\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #Dropout\n",
    "    layers.Dropout(0.25),\n",
    "    #Convolution\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    #Pooling\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolution\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    # Pooling\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolution\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    # Pooling\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Convolution\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    # Pooling\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # ベクトル化 (Flatten)\n",
    "    layers.Flatten(),\n",
    "    # 全結合層\n",
    "    layers.Dense(256, activation='relu'),\n",
    "\n",
    "    # 全結合層\n",
    "    layers.Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コンパイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ヒストリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14/14 [==============================] - 69s 5s/step - loss: 165.1337 - accuracy: 0.4667 - val_loss: 0.6936 - val_accuracy: 0.4667\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 78s 6s/step - loss: 0.6928 - accuracy: 0.5238 - val_loss: 0.7403 - val_accuracy: 0.4667\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 67s 5s/step - loss: 0.6979 - accuracy: 0.5143 - val_loss: 0.6910 - val_accuracy: 0.5333\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 63s 5s/step - loss: 0.6941 - accuracy: 0.4762 - val_loss: 0.6944 - val_accuracy: 0.4667\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 63s 4s/step - loss: 0.6936 - accuracy: 0.5143 - val_loss: 0.6952 - val_accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# モデルの学習\n",
    "history = model.fit(\n",
    "    train_x, train_t,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_x, val_t)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加終わり"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenrsoflow では定義したモデルをコンパイルする必要がありました。最適化のアルゴリズムを確率的勾配降下法 (SGD) として選択します。\n",
    "\n",
    "ここのアルゴリズムの選択と学習係数の設定も精度向上のポイントですので、[こちらの記事](https://www.tensorflow.org/guide/keras/train_and_evaluate) などを参考にしながら進めてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train に関して accuracy が 0.76, validation に関しては accuracy が 0.49 となっており、**過学習 (overfitting)** が生じていることがわかります。\n",
    "\n",
    "この辺りも踏まえて、予測の精度を上げられるように色々な手法に挑戦してみましょう。比較的簡単なところでは以下を調整してみると良いでしょう。\n",
    "\n",
    "- モデルの構成（VGG, ResNet, MobileNet など）\n",
    "- ファイチューニング\n",
    "- 最適化アルゴリズムの選択\n",
    "- 学習係数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. モデルの保存\n",
    "\n",
    "推論にて使用するために学習済みモデルをファイルに出力しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDF5 という形式で保存（TensorFlowではこちらを用いるようです）\n",
    "model.save('dog_cat_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで作業フォルダの中に `dog_cat_cnn.h5` というファイルが出力できていれば成功です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ONNX形式で出力\n",
    "\n",
    "ONNX は TensorFlow や PyTorch 問わず、モデルの形式を標準化するプロジェクトです。  \n",
    "最近では、こちらの形式に統一しておくほうが汎用性が高くなっているため、推論サーバーでは ONNX 形式を使用します。\n",
    "\n",
    "onnxruntime では通常よりも速度が速いと言われています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "onnxruntime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import keras2onnx\n",
    "#keras2onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 84 -> 40\n"
     ]
    }
   ],
   "source": [
    "# Keras -> ONNX の変換\n",
    "onnx_model = keras2onnx.convert_keras(model, model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを保存\n",
    "keras2onnx.save_model(onnx_model, 'dog_cat_cnn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "session = onnxruntime.InferenceSession('dog_cat_cnn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論に必要な構造の抽出\n",
    "session.get_modelmeta()\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv2d_input', 'dense_1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name, output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (N11onnxruntime17PrimitiveDataTypeIdEE) , expected: (N11onnxruntime17PrimitiveDataTypeIfEE)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-88b009073a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 推論\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/情報学館授業資料/s２/特論７/univ_tokyo_2020/tensorflow/venv/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Unexpected input data type. Actual: (N11onnxruntime17PrimitiveDataTypeIdEE) , expected: (N11onnxruntime17PrimitiveDataTypeIfEE)"
     ]
    }
   ],
   "source": [
    "# 推論\n",
    "y_probs = session.run([output_name], {input_name: x})[0]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル\n",
    "y = np.argmax(y_prob)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
